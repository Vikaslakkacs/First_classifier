Important points:
    Deep import of classes is important (adding classes in __init__.py constructor)

Phase 1: ##Creating basic files and folders for project start
    Create README.md and initiate git repo
    Create .gitignore and license from github and pull the project from git.
    create template.py and add all the files and folders variales and create file folders that are required for project.
    write setup.py files
    Write setup.cfg file which is about metadata of project eg; license number and type etc.,
    write pyproject.toml file
    Write down all the packages that are required in requirement.txt and requirement_dev.txt for development related packages
    Create tox.ini file with data
    Create init_setup.sh data for creating environments
    If requirements need tensorflow for M1 then init_setup_MacM1.sh has to be executed with requirements_dev.yml file.
    Code common.py in firstClassifier/utils/common.py which consists of basic configuration.
    Code firstClassifier __init__.py

    "Make this as template as it is common for all the python related ML/CNN projects"

Phase 2:## Creating initial setup and configurations for the project.
    code src/constants/__init__.py 
    Define configs/config.yaml to define the artifacts
    implement code in research for first phase of development which is "data ingestion"
    write down entities in src/firstClassifier/entity/config_entity.py and same with config/configuration.py file as well
    Create a ipynb file and create data ingestion process and later paste it in src/firstClassifier/components/data_ingestion
    copy the code to run data ingestion process to pipeline/stage_01_data_ingestion.py file
    Create ci.yml(not yaml) under .github/workflows/ci.yml: It will test the entire package whenever push happens to github.

Phase 3: ## Same as Data ingestion process but with different names.

imp noteS:
before runing dvc, dvc init has to be run first


mlflow:
install mlflow
Create Dagshub account
copy the environmental variables from dagshub with username password and uri
publish the results using mlflow methods